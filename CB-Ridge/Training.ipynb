{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the MovieLens 1M database\n",
    "[MovieLens 1M database] published by [GroupLens](https://grouplens.org). This database includes 1,000,000 (1M) ratings from about 6000 _users_ for about _4000_ movies. We can also find similar databases with about 10M, 20M ratings.\n",
    "\n",
    "We only need to care about the following files:\n",
    "\n",
    "* `u.data`: Contains all ratings of 943 _users_ for 1682 movies. Each user rates at least 20 movies. Information about rate time is also given but we do not use it in this article. \n",
    "\n",
    "* `rating_test.dat, rating_train.dat`: is a way to divide the entire data into two subsets, one for training, one for testing with a ratio of 80%-20%. \n",
    "\n",
    "* `user.dat`: Contains information about _users_, including: id, age, gender, occupation, zipcode (region), because this information can also affect _users_'s interests.\n",
    "\n",
    "* `item.dat`: information about each movie. The first few lines of the file:\n",
    "```\n",
    "1|Toy Story (1995)|January 1, 1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|1|1|1| 0|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "2|Jumanji (1995)|January 1, 1995||http://us.imdb.com/M/title-exact?Jumanji%20(1995)|0|1|0|1|0|0|0 |0|1|0|0|0|0|0|0|0|0|0|0\n",
    "```\n",
    "In each line, we will see the movie's _id_, movie name, release date, link on imdb, and the binary numbers `0`, `1` at the end to indicate which of the 19 genres the movie belongs to. given type. Information about this category will be used to build item profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Reading user file:\n",
    "u_cols =  ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-1m/user.dat', sep='|', names=u_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "n_users = users.shape[0]\n",
    "print ('Number of users:', n_users)\n",
    "# users.head() #uncomment this to see some few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training rates: 800168\n",
      "Number of test rates: 200041\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-1m/rating_train.dat', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-1m/rating_test.dat', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.to_numpy()\n",
    "rate_test = ratings_test.to_numpy()\n",
    "\n",
    "print ('Number of training rates:', rate_train.shape[0])\n",
    "print ('Number of test rates:', rate_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Build item profiles\n",
    "\n",
    "The important job in the Content-Based recommendation system is to build a profile for each item, that is, a feature vector for each item. First of all, we need to load all information about _items_ into the variable `items`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 3883\n"
     ]
    }
   ],
   "source": [
    "#Reading items file:\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "items = pd.read_csv('ml-1m/item.dat', sep='|', names=i_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "n_items = items.shape[0]\n",
    "print ('Number of items:', n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Only care about the 19 binary values ​​at the end of each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'Toy Story (1995)' '01-Jan-1995' ... 0 0 0]\n",
      " [2 'Jumanji (1995)' '01-Jan-1995' ... 0 0 0]\n",
      " [3 'Grumpier Old Men (1995)' '01-Jan-1995' ... 0 0 0]\n",
      " ...\n",
      " [3950 'Tigerland (2000)' '01-Jan-2000' ... 0 0 0]\n",
      " [3951 'Two Family House (2000)' '01-Jan-2000' ... 0 0 0]\n",
      " [3952 'Contender, The (2000)' '01-Jan-2000' ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X0 = items.to_numpy()\n",
    "X_train_counts = X0[:, -19:]\n",
    "print (X0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will build a feature vector for each item based on the movie genre matrix and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.72890105 ... 0.         0.         0.        ]\n",
      " [0.         0.4998135  0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
    "tfidf = transformer.fit_transform(X_train_counts.tolist()).toarray()\n",
    "print (tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, each row of `tfidf` corresponds to the feature vector of a movie.\n",
    "\n",
    "Next, for each _user_, we need to build which movies that _user_ has _rated_, and the value of those _ratings_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_items_rated_by_user(rate_matrix, user_id):\n",
    "    \"\"\"\n",
    "    return (item_ids, scores)\n",
    "    \"\"\"\n",
    "    y = rate_matrix[:,0] # all users\n",
    "    # item indices rated by user_id\n",
    "    # we need to +1 to user_id since in the rate_matrix, id starts from 1 \n",
    "    # but id in python starts from 0\n",
    "    ids = np.where(y == user_id +1)[0] \n",
    "    item_ids = rate_matrix[ids, 1] - 1 # index starts from 0 \n",
    "    scores = rate_matrix[ids, 2]\n",
    "    return (item_ids, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now, we can find out the Ridge Regression's coefficient for each _user_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the coefficient `W` and `b`, _ratings_ for each _items_ are predicted by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30243023 -0.30668165  3.08438071 ...  1.2104714   0.52077892\n",
      "   0.13176732]\n",
      " [-1.1797542   1.00993362  0.3713706  ... -1.29414489  1.53748308\n",
      "  -0.11726785]\n",
      " [ 1.30028656  0.61205063 -1.63814676 ...  2.82143938 -0.81340502\n",
      "   0.12741224]\n",
      " ...\n",
      " [ 0.05344967  0.15691763  1.03006534 ...  2.53039548  0.29288775\n",
      "  -0.9079871 ]\n",
      " [ 0.          1.05541271  0.28957891 ...  0.          0.\n",
      "   0.0211495 ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "[[4.50909544 2.86727198 3.7075253  ... 1.75950551 2.92901693 3.66018486]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "d = tfidf.shape[1]  # data dimension\n",
    "W = np.zeros((d, n_users))\n",
    "b = np.zeros((1, n_users))\n",
    "\n",
    "for n in range(n_users):\n",
    "    ids, scores = get_items_rated_by_user(rate_train, n)\n",
    "    \n",
    "    if len(ids) > 0:\n",
    "        max_id = max(ids)\n",
    "        if max_id >= tfidf.shape[0]:\n",
    "            new_shape = (max_id + 1, tfidf.shape[1])\n",
    "            tfidf_temp = np.zeros(new_shape)\n",
    "            tfidf_temp[:tfidf.shape[0], :] = tfidf\n",
    "        else:\n",
    "            tfidf_temp = tfidf\n",
    "\n",
    "        clf = Ridge(alpha=0.01, fit_intercept=True)\n",
    "        Xhat = tfidf_temp[ids, :]\n",
    "        \n",
    "        clf.fit(Xhat, scores)\n",
    "        W[:, n] = clf.coef_\n",
    "        b[0, n] = clf.intercept_\n",
    "    else:\n",
    "        print(f\"No items rated by user {n}\")\n",
    "\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.98328148 3.98587726 3.1059481  ... 4.08274266 2.81757845 3.53099594]\n",
      " [3.42609478 4.6874466  2.2549113  ... 1.11267442 4.84296543 3.78592335]\n",
      " [4.33098398 4.03759697 4.14102968 ... 3.03716871 4.21251547 3.66299828]\n",
      " ...\n",
      " [4.24833163 4.01264743 3.44837918 ... 4.0174268  3.94924483 3.646784  ]\n",
      " [4.24833163 4.01264743 3.44837918 ... 4.0174268  3.94924483 3.646784  ]\n",
      " [3.76728843 3.94184484 3.79353906 ... 2.50501085 4.26786956 2.88143311]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predicted scores\n",
    "Yhat = tfidf.dot(W) + b\n",
    "print(Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example with _user_ whose _id_ is `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated movies ids: [2958 1886 2538 2745 2638  356 1562  787 3808 2794 1752 1545  453 2328\n",
      " 1672  332 2430 1746 3181 1664 1243  341  355]\n",
      "True ratings: [5 2 4 4 2 1 5 1 5 5 4 4 2 5 3 4 2 3 1 2 4 3 5]\n",
      "Predicted ratings: [4.45249714 4.91901155 4.91901155 4.45249714 4.83573704 4.53589923\n",
      " 4.8224865  4.48765186 4.68228948 4.54059856 4.60611225 5.10255803\n",
      " 4.7697096  4.91901155 4.66613744 5.19536749 4.48765186 4.91901155\n",
      " 4.91901155 4.73870491 5.19536749 4.73183024 4.60611225]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "ids, scores = get_items_rated_by_user(rate_test, 10)\n",
    "Yhat[n, ids]\n",
    "print ('Rated movies ids:', ids)\n",
    "print ('True ratings:', scores)\n",
    "print ('Predicted ratings:', Yhat[ids, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the found model, we will use the Root Mean Squared Error (RMSE), which is the square root of the average of the squares of the error. The error is calculated as the difference between _true rating_ and _predicted rating_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training: 1.019168710035481\n",
      "RMSE for test: 1.1641591390251866\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "def evaluate(Yhat, rates, W, b):\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for n in range(n_users):\n",
    "        ids, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        \n",
    "        if len(ids) > 0:\n",
    "            max_id = max(ids)\n",
    "            if max_id >= Yhat.shape[0]:\n",
    "                new_shape = (max_id + 1, Yhat.shape[1])\n",
    "                Yhat_temp = np.zeros(new_shape)\n",
    "                Yhat_temp[:Yhat.shape[0], :] = Yhat\n",
    "            else:\n",
    "                Yhat_temp = Yhat\n",
    "\n",
    "        scores_pred = Yhat_temp[ids, n]\n",
    "        e = scores_truth - scores_pred\n",
    "        se += (e * e).sum(axis=0)\n",
    "        cnt += e.size\n",
    "    return sqrt(se / cnt)\n",
    "\n",
    "print('RMSE for training:', evaluate(Yhat, rate_train, W, b))\n",
    "print('RMSE for test:', evaluate(Yhat, rate_test, W, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we evaluate the Mean Average Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for training: 0.7806232997638736\n",
      "MAE for test: 0.9050784338561105\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def evaluate_mae(Yhat, rates, W, b):\n",
    "    ae = 0\n",
    "    cnt = 0\n",
    "    n_users = Yhat.shape[1]  # số lượng người dùng\n",
    "    for n in range(n_users):\n",
    "        ids, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        \n",
    "        if len(ids) > 0:\n",
    "            max_id = max(ids)\n",
    "            if max_id >= Yhat.shape[0]:\n",
    "                new_shape = (max_id + 1, Yhat.shape[1])\n",
    "                Yhat_temp = np.zeros(new_shape)\n",
    "                Yhat_temp[:Yhat.shape[0], :] = Yhat\n",
    "            else:\n",
    "                Yhat_temp = Yhat\n",
    "\n",
    "        scores_pred = Yhat_temp[ids, n]\n",
    "        e = scores_truth - scores_pred\n",
    "        ae += np.sum(np.abs(e))\n",
    "        cnt += e.size\n",
    "    return abs(ae / cnt) \n",
    "\n",
    "print('MAE for training:', evaluate_mae(Yhat, rate_train, W, b))\n",
    "print('MAE for test:', evaluate_mae(Yhat, rate_test, W, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Thus, with the training set, the RMSE is about _1.02_, while MAE is _0.78_ ; With the test set, the error is slightly larger, about _1.16_ and _0.90_. We see that this result is not really good because we have simplified the model too much. Better results can be seen in the other two models that we have in this project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
